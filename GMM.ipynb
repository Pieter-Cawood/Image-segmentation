{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import json\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from cachier import cachier\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from skimage import img_as_float32\n",
    "import cv2 as cv2\n",
    "from math import pi, e, sqrt, cos, sin\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load puzzle images, masks & corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm = partial(tqdm, position=0, leave=True)\n",
    "cachier = partial(cachier, pickle_reload=False, cache_dir='data/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Images: 100%|██████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 35.07it/s]\n",
      "Loading Masks: 100%|██████████████████████████████████████████████████████████████████| 48/48 [00:00<00:00, 219.20it/s]\n"
     ]
    }
   ],
   "source": [
    "SIZE = (768, 1024)\n",
    "\n",
    "DATA_PATH_PAIRS = list(zip(\n",
    "    natsorted(glob(f'./data/images-{SIZE[1]}x{SIZE[0]}/*.png')),\n",
    "    natsorted(glob(f'./data/masks-{SIZE[1]}x{SIZE[0]}/*.png')),\n",
    "))\n",
    "DATA_IMGS = np.array(\n",
    "    [img_as_float32(imageio.imread(img_path)) for img_path, _ in tqdm(DATA_PATH_PAIRS, 'Loading Images')])\n",
    "DATA_MSKS = np.array(\n",
    "    [img_as_float32(imageio.imread(msk_path)) for _, msk_path in tqdm(DATA_PATH_PAIRS, 'Loading Masks')])\n",
    "\n",
    "assert DATA_IMGS.shape == (48, SIZE[0], SIZE[1], 3)\n",
    "assert DATA_MSKS.shape == (48, SIZE[0], SIZE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/corners.json', mode='r') as f:\n",
    "    DATA_CORNER_NAMES, DATA_CORNERS = json.load(f)\n",
    "    DATA_CORNERS = np.array(DATA_CORNERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(data):\n",
    "    return np.subtract(data, np.min(data))/ np.subtract(np.max(data), np.min(data))\n",
    "\n",
    "def show_image(image,cs=False,cmap= None, title=None):\n",
    "    if cs:\n",
    "        norm_img = normalise_data(image)\n",
    "    else:\n",
    "        norm_img = image\n",
    "    plt.title(title)\n",
    "    plt.imshow(norm_img, cmap= cmap)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ImageFeatures(object):\n",
    "    \n",
    "    def _get_kernel(self, g, sigma, size, k=None):   \n",
    "        \"\"\"\n",
    "        Function to map kernel function to numpy matrix, \n",
    "        Note result is normalized.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Center x and y coordinates and return a numpy matrix from g function\n",
    "        kernel =  np.fromfunction(lambda x, y: \n",
    "                                 g((x - (size - 1) / 2), (y - (size - 1) / 2), sigma, k),\n",
    "                                 (size, size))  \n",
    "        return kernel.astype(np.float32)\n",
    "\n",
    "    def dog(self, sigma, size, k):\n",
    "        \"\"\"\n",
    "        Get a Difference of Gaussian filter\n",
    "    \n",
    "        \"\"\"\n",
    "        def _g(x, y, sigma, k):\n",
    "            return (2*pi*sigma**2) * \\\n",
    "                    e**(-1 * ((x**2 + y**2) / (2 * sigma**2))) - \\\n",
    "                    (1 / 2 * pi * k**2 * sigma**2) *\\\n",
    "                    e**(-1 * ((x**2 + y**2)/(2 * k**2 * sigma**2)))\n",
    "                \n",
    "        if k <= 1.0:\n",
    "            raise ValueError(\"k must be > 1.0\")\n",
    "        \n",
    "        return self._get_kernel(_g, sigma, size, k)\n",
    "    \n",
    "    def extract(self, image, gaus=(3,3), dog_sigma=10, dog_size=49, dog_k=5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : numpy array\n",
    "        gaus : tuple of gaussian kernel for blurring input image\n",
    "        dog_sigma : int, sigma value for DoG features\n",
    "        dog_size  : int, size of DoG kernel\n",
    "        dog_k : int, k parameter for DoG \n",
    "        show_feature_plots : bool, verbose option to plot features\n",
    "        \n",
    "        Returns\n",
    "        ---------- \n",
    "        numpy array : 9 x flattened image shape (786432) features of image.\n",
    "        1 - 3: R, G, B channels\n",
    "        4 - 6: DoG of RGB channels\n",
    "        7 - 9: H, S, V channels\n",
    "    \n",
    "        \"\"\"\n",
    "        # Gaussian blur image as a first step to reduce noise\n",
    "        image_ = cv2.GaussianBlur(image, gaus, 0).astype(np.float32)  \n",
    "        # RBG Features\n",
    "        features = None\n",
    "        for rgb_channel in cv2.split(image_):\n",
    "            if features is None:\n",
    "                features = np.array(normalise_data(rgb_channel.flatten().astype(np.float32)))\n",
    "            else:\n",
    "                features = np.vstack((features, normalise_data(rgb_channel.flatten().astype(np.float32))))\n",
    "                \n",
    "        # DoG features\n",
    "        dog_kernel = self.dog(dog_sigma, dog_size, dog_k)\n",
    "        convolved = cv2.filter2D(image_, -1, dog_kernel)              \n",
    "        for convolved_rgb_channel in cv2.split(convolved):\n",
    "            features = np.vstack((features, normalise_data(convolved_rgb_channel.flatten().astype(np.float32))))\n",
    "\n",
    "        # HSV features\n",
    "        hsv_image = cv2.cvtColor(image_, cv2.COLOR_RGB2HSV)\n",
    "        for hsv_channel in cv2.split(hsv_image):\n",
    "            features = np.vstack((features, normalise_data(hsv_channel.flatten().astype(np.float32))))\n",
    "  \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate gaussian to model a single puzzle piece\n",
    "This is just to visualise the distribution for a single puzzle piece's foreground and background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(feature_data, mask, invert_mask = False):\n",
    "    \"\"\"\n",
    "    Applies a mask to the data, and\n",
    "    retrieves the pdf parameters for a single distribtution.\n",
    "\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    mask_ = mask.astype(np.bool).flatten()\n",
    "    if invert_mask:\n",
    "        mask_ = np.invert(mask_)\n",
    "    for feature in feature_data:\n",
    "        masked_feature = feature[mask_ == True]\n",
    "        # Append masked-normalised feature\n",
    "        data.append(masked_feature.flatten())\n",
    "    data = np.array(data)\n",
    "    return data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foreground of first piece**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extractor = ImageFeatures()\n",
    "features = features_extractor.extract(DATA_IMGS[0])\n",
    "fg_data = get_training_data(features, DATA_MSKS[0], invert_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background of first piece**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_data = get_training_data(features, DATA_MSKS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is composed of intensities that might be modelled using gaussian distributions, we investigate the use of a Mixture Gausssian Model (GMM), which is an unsupervised learning approach that aims to fit a mixture of gasussian distributions to model the data with $d$ dimensions of features. And we want to use the GMM to fit clusters or mixture of gaussians to our data set, but we do not know where they are, or how they are shaped.\n",
    "It differs from normal KNN, since the clusters are gaussian distributions, which are parameterised by a mean and covariance. Which allows us to model the probability that our data belongs to either clusters in elliptical shapes, as opposed to the circular shapes clustered by KNN.\n",
    "\n",
    "![GMM](resources/GMM_illistration.png)\n",
    "\n",
    "### Expectation Maximisation (EM)\n",
    "We find the gaussian mixture model by using the EM algorithm to find k to minimize $\\frac{(x-u_k)^2}{\\sigma^2}$.\n",
    "EM introduces a latent variable $h$ for each cluster $K$, and the GMM is a marginalisation of the joint probability distribution $P(\\vec{x}, h)$, where $\\vec{x}$ represents our feature vectors.  We define a variable $h \\in \\{1 \\dots K\\}$ and then the probability distribution for each categorical variable is written as <br>\n",
    "$Pr(\\times|h, \\theta) = Norm_x[\\mu_h, \\Sigma_h]$ <br>\n",
    "$Pr(h|\\theta) = Cat_h[\\lambda]$ <br>\n",
    "\n",
    "Then we can recover the density by marginalising out the $h$ from the joint probability distribution $Pr(\\vec{x},h)$ <br>\n",
    "$\n",
    "\\begin{align}\n",
    "Pr(\\vec{x}|\\theta) & = \\sum^K_{k=1} Pr(\\vec{x}, h = k | \\theta)\\\\\n",
    "                   & = \\sum^K_{k=1} Pr(\\vec{x}, h = k, \\theta) Pr(h=k|\\theta)\\\\\n",
    "                   & = \\sum^K_{k=1} \\lambda_k Norm_\\vec{x}[\\mu_k, \\Sigma_h]   \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "![GMM](resources/GMM_marginilisation.png)\n",
    "\n",
    "This formulation allows us to fit the model with the Expectation Maximisation algorithm using closed-form solutions in an iterative process. The goal is to learn the model parameters $\\theta = \\{\\lambda_{1 \\dots K}, \\mu_{1 \\dots K}, \\Sigma_{1 \\dots K} \\}$ from our training features $\\vec{x}$. The two steps of the EM algorithm include\n",
    "\n",
    "#### 1. E-Step (Expectation)\n",
    "The probability of $h$ is computed using the current estimates of the parameters $\\theta$. So for each point we estimate the probability that each Gaussian generated it $Pr(h_i = k | \\vec{x}_i, \\theta^{[t]})$, which might also be described as the responsibility of the $k^{th}$ Gaussian for the $i^{th}$ data point expressed by <br>\n",
    "$r_{ik} = \\frac{\\lambda_k Norm_{x_i} [\\mu_k, \\Sigma_k]}{\\sum^K_{j=1}\\lambda_j Norm_\\vec{x_i} [\\mu_j, \\Sigma_j]}$\n",
    "\n",
    "![GMM](resources/GMM_Estep.png)\n",
    "\n",
    "\n",
    "#### 1. M-Step (Maximisation)\n",
    "Using the computed resposibilities the maximisation step then updates the model parameters $\\theta$. And in our case we use maximum likelihood estimation that allows the following closed form update rules <br>\n",
    "\n",
    "\n",
    "$\\lambda_k^{[t + 1]} = \\frac{\\sum^I_{i=1} r_{ik}} {\\sum^K_{j=1}\\sum^I_{i=1} r_{ij}  }   $\n",
    "\n",
    "$\\mu_k^{[t + 1]} = \\frac{\\sum^I_{i=1} r_{ik} \\vec{x_i}} {\\sum^I_{i=1} r_{ik}} $\n",
    "\n",
    "$\\Sigma_k^{[t + 1]} = \\frac{\\sum^I_{i=1} r_{ik} (\\vec{x_i} - \\mu_k^{[t + 1]}) (\\vec{x_i} - \\mu_k^{[t + 1]})^T}{\\sum^I_{i=1} r_{ik}}$\n",
    "\n",
    "![GMM](resources/GMM_Mstep.png)\n",
    "\n",
    "#### The EM-flow\n",
    "![EM](resources/EM_flow.png)\n",
    "- The $k$ clusters center are randomly initialised \n",
    "- The responsibilities are recomputed during the E-Step, and the model parameters are updated during the M-Step.\n",
    "- The iterative process is repeated until convergence (Parameter change is smaller then some threshold.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuassianParameters(object):\n",
    "    \"\"\"Distribution parameters\"\"\"\n",
    "\n",
    "    def __init__(self, lmbda, mu, cov):\n",
    "        self.lmbda = lmbda\n",
    "        self.mu = mu\n",
    "        self.cov = cov\n",
    "\n",
    "    def difference_between(self, other):\n",
    "        return abs(self.lmbda - other.lmbda) + \\\n",
    "               euclidean(self.mu, other.mu) + \\\n",
    "               euclidean(self.cov.flatten(), other.cov.flatten())\n",
    "\n",
    "\n",
    "class GaussianMixtureModel(object):\n",
    "    \"\"\"Multivariate Gaussian Mixture Model\"\"\"\n",
    "\n",
    "    def _get_init_params(self, X):\n",
    "        n_features = X.shape[1]\n",
    "        # Initial weigths evenly distributed\n",
    "        lmbda = 1 / self.k_size\n",
    "        # Initial means, random observations from input data\n",
    "        mu = np.random.choice(X.flatten(), n_features)\n",
    "        # Iniital covariance\n",
    "        cov = np.random.random((n_features, n_features))\n",
    "        cov *= cov.T\n",
    "        cov += n_features * np.eye(n_features)\n",
    "        return GuassianParameters(lmbda, mu, cov)\n",
    "\n",
    "    def __init__(self, n_k=3, n_runs=5, tol=1e-4, max_iter=100, verbose=True):\n",
    "        self.fitted = False\n",
    "        self.k_size = n_k\n",
    "        self.n_runs = n_runs\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.verbose = verbose\n",
    "        self.fitted_parameters = None\n",
    "\n",
    "    def _estep(self, X, gaussian_parameters):\n",
    "        \"\"\"Calculate the responsibility for each cluster for all of the data points,\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        responsibilities = np.zeros((n_samples, self.k_size))\n",
    "        weighted_gaussians = np.zeros((n_samples, self.k_size))\n",
    "        # Get normal distributions using current parameter set\n",
    "        for k in range(self.k_size):\n",
    "            weighted_gaussians[:, k] = gaussian_parameters[k].lmbda * \\\n",
    "                                       multivariate_normal.pdf(X, gaussian_parameters[k].mu, gaussian_parameters[k].cov)\n",
    "        # Compute responsibility for each cluster\n",
    "        for k in range(self.k_size):\n",
    "            responsibilities[:, k] = weighted_gaussians[:, k] / np.sum(weighted_gaussians, axis=1, initial=1e-10)\n",
    "        return responsibilities\n",
    "\n",
    "    def _mstep(self, X, responsibilities):\n",
    "        \"\"\"Compute model parameters using maximum likelikhood closed form solutions\"\"\"\n",
    "        gaussian_parameters = []\n",
    "        for k in range(self.k_size):\n",
    "            k_sum_responsibility = np.sum(responsibilities[:, k])\n",
    "            lmbda = k_sum_responsibility / (np.sum(np.sum(responsibilities, axis=1)))\n",
    "            mu = np.dot(responsibilities[:, k], X) / k_sum_responsibility\n",
    "            standardised_x = X - mu\n",
    "            cov = np.dot((standardised_x.T * responsibilities[:, k]), standardised_x) / k_sum_responsibility\n",
    "            # Add small value to diagonal to prevent singular matrix\n",
    "            cov += np.eye(len(cov)) * 1e-10\n",
    "            gaussian_parameters.append(GuassianParameters(lmbda, mu, cov))\n",
    "        return gaussian_parameters\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit the model according to the given training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array, of shape (n_samples, n_features)\n",
    "            Training vector, where n_samples is the number of samples/pixels and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        \"\"\"\n",
    "        converged = False\n",
    "        run_iteration = 1\n",
    "        # Initialise parameters\n",
    "        gaussian_parameters = [self._get_init_params(X) for _k in range(self.k_size)]\n",
    "        while not converged and run_iteration <= self.max_iter:\n",
    "            # E-step\n",
    "            responsibilities = self._estep(X, gaussian_parameters)\n",
    "            # M-step\n",
    "            new_gaussian_parameters = self._mstep(X, responsibilities)\n",
    "            # Iterate until parameters experience change smaller than tolerance\n",
    "            total_change = 0\n",
    "            for k, parameters in enumerate(new_gaussian_parameters):\n",
    "                total_change += parameters.difference_between(gaussian_parameters[k])\n",
    "            if total_change < self.tol:\n",
    "                converged = True\n",
    "            gaussian_parameters = new_gaussian_parameters\n",
    "            if self.verbose:\n",
    "                print(\"Iteration #{0}, change in parameters {1}\".format(run_iteration, total_change))\n",
    "            run_iteration += 1\n",
    "            \n",
    "        self.fitted_parameters = gaussian_parameters\n",
    "        self.fitted = True\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Finished in {0} iterations\".format(run_iteration - 1))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict's the probability density the input observations by marginalising\n",
    "        out the joint probability distributions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array, of shape (n_samples, n_features)\n",
    "            Testing vector, where n_samples is the number of samples/pixels and\n",
    "            n_features is the number of features.\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        y : numpy array, of shape (n_samples)\n",
    "            Estimated probability density from the mixture of gaussian models.\n",
    "        \"\"\"\n",
    "        assert self.fitted, \"Model is not yet fitted.\"\n",
    "        n_samples = X.shape[0]\n",
    "        gaussian_pdfs = np.zeros((n_samples, self.k_size))\n",
    "        for k in range(self.k_size):\n",
    "            gaussian_pdfs[:, k] = self.fitted_parameters[k].lmbda *\\\n",
    "            multivariate_normal.pdf(X, self.fitted_parameters[k].mu, self.fitted_parameters[k].cov)\n",
    "        return np.sum(gaussian_pdfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_gmm = GaussianMixtureModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1, change in parameters 86.78486886210865\n",
      "Iteration #2, change in parameters 0.048852571379784306\n",
      "Iteration #3, change in parameters 0.24146411450648414\n",
      "Iteration #4, change in parameters 0.7341891267436587\n",
      "Iteration #5, change in parameters 0.33987194003847276\n",
      "Iteration #6, change in parameters 0.2490303534813161\n",
      "Iteration #7, change in parameters 0.08862317168041003\n",
      "Iteration #8, change in parameters 0.05040095695188027\n",
      "Iteration #9, change in parameters 0.05785165006748533\n",
      "Iteration #10, change in parameters 0.037719199204924794\n",
      "Iteration #11, change in parameters 0.025459351060073614\n",
      "Iteration #12, change in parameters 0.017447920462190007\n",
      "Iteration #13, change in parameters 0.011821873492042057\n",
      "Iteration #14, change in parameters 0.008284855519583917\n",
      "Iteration #15, change in parameters 0.006061208611136909\n",
      "Iteration #16, change in parameters 0.00459335768169061\n",
      "Iteration #17, change in parameters 0.003570511257021504\n",
      "Iteration #18, change in parameters 0.00281882651401748\n",
      "Iteration #19, change in parameters 0.002243091565485391\n",
      "Iteration #20, change in parameters 0.0017924006698171627\n",
      "Iteration #21, change in parameters 0.0014378644539980111\n",
      "Iteration #22, change in parameters 0.0011637913513672588\n",
      "Iteration #23, change in parameters 0.0009705350224306586\n",
      "Iteration #24, change in parameters 0.0008785229364845206\n",
      "Iteration #25, change in parameters 0.0009008355558949487\n",
      "Iteration #26, change in parameters 0.0010412377975368861\n",
      "Iteration #27, change in parameters 0.0013236281918941218\n",
      "Iteration #28, change in parameters 0.0018533825582291838\n",
      "Iteration #29, change in parameters 0.002753644013209544\n",
      "Iteration #30, change in parameters 0.004252563304188611\n",
      "Iteration #31, change in parameters 0.005988470277657715\n",
      "Iteration #32, change in parameters 0.006884729237441983\n",
      "Iteration #33, change in parameters 0.008397596017445559\n",
      "Iteration #34, change in parameters 0.009727099660832385\n",
      "Iteration #35, change in parameters 0.010763467496796911\n",
      "Iteration #36, change in parameters 0.011134244195878745\n",
      "Iteration #37, change in parameters 0.010576375803817569\n",
      "Iteration #38, change in parameters 0.009582205429851868\n",
      "Iteration #39, change in parameters 0.008499184624583545\n",
      "Iteration #40, change in parameters 0.0074820544212847225\n",
      "Iteration #41, change in parameters 0.006553250129511362\n",
      "Iteration #42, change in parameters 0.005687105597089365\n",
      "Iteration #43, change in parameters 0.004860625286013297\n",
      "Iteration #44, change in parameters 0.004078206129237231\n",
      "Iteration #45, change in parameters 0.0033606960754803353\n",
      "Iteration #46, change in parameters 0.0027294641688683217\n",
      "Iteration #47, change in parameters 0.0021951779098072777\n",
      "Iteration #48, change in parameters 0.001756144382050326\n",
      "Iteration #49, change in parameters 0.0014024929978510713\n",
      "Iteration #50, change in parameters 0.0011209625836050125\n",
      "Iteration #51, change in parameters 0.000898105319880541\n",
      "Iteration #52, change in parameters 0.0007218997813872462\n",
      "Iteration #53, change in parameters 0.000582363351243345\n",
      "Iteration #54, change in parameters 0.00047149576599041525\n",
      "Iteration #55, change in parameters 0.00038309774002675347\n",
      "Iteration #56, change in parameters 0.0003123234363993355\n",
      "Iteration #57, change in parameters 0.0002553968723551361\n",
      "Iteration #58, change in parameters 0.00020938590456231964\n",
      "Iteration #59, change in parameters 0.0001720373752350548\n",
      "Iteration #60, change in parameters 0.0001416052075969508\n",
      "Iteration #61, change in parameters 0.00011673196056054495\n",
      "Iteration #62, change in parameters 9.635337722804931e-05\n",
      "Finished in 62 iterations\n"
     ]
    }
   ],
   "source": [
    "bg_gmm.fit(bg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_gmm = GaussianMixtureModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1, change in parameters 87.43231049940185\n",
      "Iteration #2, change in parameters 0.0335382575248943\n",
      "Iteration #3, change in parameters 0.18871187532155315\n",
      "Iteration #4, change in parameters 0.5387847121145284\n",
      "Iteration #5, change in parameters 0.3661688243310085\n",
      "Iteration #6, change in parameters 0.18915660613554253\n",
      "Iteration #7, change in parameters 0.11655352078391654\n",
      "Iteration #8, change in parameters 0.07278904508064482\n",
      "Iteration #9, change in parameters 0.06790504819557583\n",
      "Iteration #10, change in parameters 0.06428643003174347\n",
      "Iteration #11, change in parameters 0.06328724259818112\n",
      "Iteration #12, change in parameters 0.070107731524067\n",
      "Iteration #13, change in parameters 0.08358815215651837\n",
      "Iteration #14, change in parameters 0.1289837113546957\n",
      "Iteration #15, change in parameters 0.19478864460677797\n",
      "Iteration #16, change in parameters 0.22304386467502874\n",
      "Iteration #17, change in parameters 0.19010102449983157\n",
      "Iteration #18, change in parameters 0.12041195113367315\n",
      "Iteration #19, change in parameters 0.0940947861335649\n",
      "Iteration #20, change in parameters 0.09090240171554191\n",
      "Iteration #21, change in parameters 0.09812812710131395\n",
      "Iteration #22, change in parameters 0.12494904952387828\n",
      "Iteration #23, change in parameters 0.1789526446113868\n",
      "Iteration #24, change in parameters 0.05767874834963034\n",
      "Iteration #25, change in parameters 0.030722477638154548\n",
      "Iteration #26, change in parameters 0.02904922180595539\n",
      "Iteration #27, change in parameters 0.02242488172509638\n",
      "Iteration #28, change in parameters 0.017995422935559897\n",
      "Iteration #29, change in parameters 0.014760369740599598\n",
      "Iteration #30, change in parameters 0.013300254424858438\n",
      "Iteration #31, change in parameters 0.01673206506258626\n",
      "Iteration #32, change in parameters 0.020156418028980487\n",
      "Iteration #33, change in parameters 0.021684635308647414\n",
      "Iteration #34, change in parameters 0.021441083339659252\n",
      "Iteration #35, change in parameters 0.019741084240692337\n",
      "Iteration #36, change in parameters 0.017375427831752513\n",
      "Iteration #37, change in parameters 0.01486941987455308\n",
      "Iteration #38, change in parameters 0.012445325039548283\n",
      "Iteration #39, change in parameters 0.010213602131092793\n",
      "Iteration #40, change in parameters 0.008261764342361809\n",
      "Iteration #41, change in parameters 0.006616444718270636\n",
      "Iteration #42, change in parameters 0.00525688316977409\n",
      "Iteration #43, change in parameters 0.004149329022376356\n",
      "Iteration #44, change in parameters 0.003258383335743985\n",
      "Iteration #45, change in parameters 0.002549107307321271\n",
      "Iteration #46, change in parameters 0.0019888627561096346\n",
      "Iteration #47, change in parameters 0.0015488010117648866\n",
      "Iteration #48, change in parameters 0.0012044945253277916\n",
      "Iteration #49, change in parameters 0.0009358168547630901\n",
      "Iteration #50, change in parameters 0.0007265849463617895\n",
      "Iteration #51, change in parameters 0.0005638497434257606\n",
      "Iteration #52, change in parameters 0.00043741914749923503\n",
      "Iteration #53, change in parameters 0.0003392442236877164\n",
      "Iteration #54, change in parameters 0.0002630570895236105\n",
      "Iteration #55, change in parameters 0.0002039474626520839\n",
      "Iteration #56, change in parameters 0.00015810664535825667\n",
      "Iteration #57, change in parameters 0.00012255603853364617\n",
      "Iteration #58, change in parameters 9.501315568928889e-05\n",
      "Finished in 58 iterations\n"
     ]
    }
   ],
   "source": [
    "fg_gmm.fit(fg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_densities = bg_gmm.predict(features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_densities = fg_gmm.predict(features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fg_densities / (0.4*fg_densities + 0.3*bg_densities + 1e-10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = test < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pop.astype(int).reshape(SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(pop, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
