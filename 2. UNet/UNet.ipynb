{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, concatenate, Dense, Softmax\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import json\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from cachier import cachier\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from skimage import img_as_float32\n",
    "import cv2 as cv2\n",
    "from math import pi, e, sqrt, cos, sin\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztqdm = partial(tqdm, position=0, leave=True)\n",
    "cachier = partial(cachier, pickle_reload=False, cache_dir='data/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Images: 100%|██████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 36.42it/s]\n",
      "Loading Masks: 100%|██████████████████████████████████████████████████████████████████| 48/48 [00:00<00:00, 262.32it/s]\n"
     ]
    }
   ],
   "source": [
    "SIZE = (768, 1024)\n",
    "NEW_SIZE = (256, 192)\n",
    "DATA_PATH_PAIRS = list(zip(\n",
    "    natsorted(glob(f'../data/images-{SIZE[1]}x{SIZE[0]}/*.png')),\n",
    "    natsorted(glob(f'../data/masks-{SIZE[1]}x{SIZE[0]}/*.png')),\n",
    "))\n",
    "DATA_IMGS = np.array(\n",
    "    [cv2.resize(img_as_float32(imageio.imread(img_path)), NEW_SIZE) for img_path, _ in tqdm(DATA_PATH_PAIRS, 'Loading Images')])\n",
    "DATA_MSKS = np.array(\n",
    "    [cv2.resize(img_as_float32(imageio.imread(msk_path)), NEW_SIZE) for _, msk_path in tqdm(DATA_PATH_PAIRS, 'Loading Masks')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/corners.json', mode='r') as f:\n",
    "    DATA_CORNER_NAMES, DATA_CORNERS = json.load(f)\n",
    "    DATA_CORNERS = np.array(DATA_CORNERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(data):\n",
    "    return np.subtract(data, np.min(data))/ np.subtract(np.max(data), np.min(data))\n",
    "\n",
    "def show_image(image,cs=False,cmap= None, title=None):\n",
    "    if cs:\n",
    "        norm_img = normalise_data(image)\n",
    "    else:\n",
    "        norm_img = image\n",
    "    plt.title(title)\n",
    "    plt.imshow(norm_img, cmap= cmap)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataUtils(object):\n",
    "    \n",
    "    def train_test_split(self, images, masks, corners, train_size=0.7, validation_size=0.15, test_size=0.15):\n",
    "        all_indices = np.arange(len(images))\n",
    "        np.random.shuffle(all_indices)\n",
    "        train_indices = all_indices[0: int(len(images)* train_size) + 1]\n",
    "        validate_inidices = all_indices[len(train_indices): len(train_indices) + int(len(images)* validation_size)]\n",
    "        test_indices = all_indices[len(train_indices)+len(validate_inidices): len(train_indices)+len(validate_inidices)+ int(len(images)* test_size)]\n",
    "\n",
    "        train_images = np.array([images[i] for i in train_indices])\n",
    "        train_masks = np.array([masks[i] for i in train_indices])\n",
    "        train_corners = np.array([corners[i] for i in train_indices])\n",
    "        \n",
    "        validate_images = np.array([images[i] for i in validate_inidices])\n",
    "        validate_masks = np.array([masks[i] for i in validate_inidices])\n",
    "        validate_corners = np.array([corners[i] for i in validate_inidices])\n",
    "        \n",
    "        test_images = np.array([images[i] for i in test_indices])\n",
    "        test_masks = np.array([masks[i] for i in test_indices])\n",
    "        test_corners = np.array([corners[i] for i in test_indices])\n",
    "        \n",
    "        return train_images, train_masks, train_corners,\\\n",
    "               validate_images, validate_masks, validate_corners,\\\n",
    "               test_images, test_masks, test_corners\n",
    "\n",
    "\n",
    "    def get_augmented(self, image, mask, gaus=(3, 3)):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # RGB image\n",
    "        image_list = [normalise_data(image.astype(np.float32))]\n",
    "        mask_list = [normalise_data(mask.astype(np.float32))]\n",
    "        \n",
    "        # Gaussian blurred image\n",
    "        image_ = cv2.GaussianBlur(image, gaus, 0).astype(np.float32)  \n",
    "        image_list.append(normalise_data(image_))\n",
    "        mask_list.append(normalise_data(mask.astype(np.float32)))\n",
    "        \n",
    "        # Vertical flip image \n",
    "        image_ = cv2.flip(image, 0)\n",
    "        image_list.append(normalise_data(image_))\n",
    "        mask_ = cv2.flip(mask, 0)\n",
    "        mask_list.append(normalise_data(mask_.astype(np.float32)))\n",
    "        \n",
    "        # Horizontal flip image\n",
    "        image_ = cv2.flip(image, 1)\n",
    "        image_list.append(normalise_data(image_))\n",
    "        mask_ = cv2.flip(mask, 1)\n",
    "        mask_list.append(normalise_data(mask_.astype(np.float32)))\n",
    "        \n",
    "        return image_list, mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, validation and training split\n",
    "Split data randomly into sets of 70% training, 15% validation and 15% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils = ImageDataUtils()\n",
    "\n",
    "train_images, train_masks, train_corners, \\\n",
    "validate_images, validate_masks, validate_corners, \\\n",
    "test_images, test_masks, test_corners = data_utils.train_test_split(DATA_IMGS, DATA_MSKS, DATA_CORNERS,\n",
    "                                                                    train_size=0.7, validation_size=0.15, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data:\n",
    "Create augmented training set (Includes pre-processing of images and masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = []\n",
    "augmented_masks = []\n",
    "\n",
    "for train_image, train_mask in zip(train_images, train_masks):\n",
    "    image_list, mask_list = data_utils.get_augmented(train_image, train_mask)\n",
    "    augmented_data += image_list\n",
    "    augmented_masks += mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process the validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data = np.array([normalise_data(validate_image) for validate_image in validate_images])\n",
    "test_data = np.array([normalise_data(test_image) for test_image in test_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16\n",
    "\n",
    "The VGG16 model proposed was tested using the ImageNet data set, which contains over 15 million hand labeled high-resolution images, that belong to around 22-thousand categories. The model was trained for weeks, and pre-trained models are commonly available using deep learning APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 192, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 192, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 192, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 96, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 96, 128, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 96, 128, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 48, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 48, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 48, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 48, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 24, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 24, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 24, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 24, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_pretrained = VGG16(include_top=False, weights='imagenet', input_shape=(192,256,3))\n",
    "vgg16_pretrained.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The U-Net architecture\n",
    "U-Net was originally published as a convolutional network for biomedical image segmentation.\n",
    "The UNet model was named after its U-shape that consists of two paths, which are commonly reffered to in deep learning as the encoder- and\n",
    "decoder networks. UNet's encoder captures the context of input images, and it contains a symmetric decoder that allows to localization using a technique called upsampling (fractional convolution or transposed convolution.) \n",
    "<br><br>\n",
    "![Unet](resources/Unet.PNG)\n",
    "\n",
    "\n",
    "### VGG16-U-Net\n",
    "The idea is to use the pre-trained VGG16 model as the encoder to a U-Net model, and also to construct a symmetric decoder network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGUnet(object):\n",
    "    \n",
    "    def __init__(self, input_shape=(192, 256, 3), num_classes=2):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self._build_model(self.input_shape, self.num_classes)\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def summary(self):\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def _build_model(self, input_shape, num_classes):\n",
    "        \"\"\"Builds a UNet model from Keras' pretrained VGG16 model.\"\"\"\n",
    "        encoder = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "        \n",
    "        # Decoder block1, from Encoder output\n",
    "        encoder_output = encoder.output\n",
    "        conv_0 = Conv2D(512, 3, activation='relu', padding='same')(encoder_output)\n",
    "        conv_0_up = Conv2DTranspose(256, 3, strides=2, activation='relu', padding='same')(conv_0)\n",
    "        \n",
    "        # Decoder block 1, concat block with encoder block 5\n",
    "        concat_1 = concatenate([encoder.get_layer('block5_conv3').output, conv_0_up])\n",
    "        conv_1 = Conv2D(512, 3, activation='relu', padding='same')(concat_1)\n",
    "        conv_1_up =  Conv2DTranspose(256, 3, strides=2, activation='relu', padding='same')(conv_1)\n",
    "        \n",
    "        # Decoder block 2, concat block with encoder block 4\n",
    "        concat_2 = concatenate([encoder.get_layer('block4_conv3').output, conv_1_up])\n",
    "        conv_2 = Conv2D(512, (3, 3), activation='relu', padding='same')(concat_2)\n",
    "        conv_2_up =  Conv2DTranspose(256, 3, strides=2, activation='relu', padding='same')(conv_2)\n",
    "        \n",
    "        # Decoder block 3, concat block with encoder block 3\n",
    "        concat_3 = concatenate([encoder.get_layer('block3_conv3').output, conv_2_up])\n",
    "        conv_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat_3)\n",
    "        conv_3_up =  Conv2DTranspose(128, 3, strides=2, activation='relu', padding='same')(conv_3)\n",
    "        \n",
    "        # Decoder block 4, concat block with encoder block 2\n",
    "        concat_4 = concatenate([encoder.get_layer('block2_conv2').output, conv_3_up])\n",
    "        conv_4 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat_4)\n",
    "        conv_4_up =  Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same')(conv_4)\n",
    "        \n",
    "        # Decoder block 5, concat block with encoder block 1\n",
    "        concat_5 = concatenate([encoder.get_layer('block1_conv2').output, conv_4_up])\n",
    "        conv_5 = Conv2D(32, 3, activation='relu', padding='same')(concat_5)\n",
    "        \n",
    "        outputs = Conv2D(num_classes, 1, activation='softmax')(conv_5)\n",
    "        \n",
    "        return Model(inputs=encoder.layers[0].input, outputs=outputs)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        return self.model.train_on_batch(X, y)[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_unet = VGGUnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 192, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 192, 256, 64) 1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 192, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 96, 128, 64)  0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 96, 128, 128) 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 96, 128, 128) 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 48, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 48, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 48, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 48, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 24, 32, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 24, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 24, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 24, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 12, 16, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 12, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 12, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 12, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 6, 8, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 6, 8, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_25 (Conv2DTran (None, 12, 16, 256)  1179904     conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 12, 16, 768)  0           block5_conv3[0][0]               \n",
      "                                                                 conv2d_transpose_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 16, 512)  3539456     concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_26 (Conv2DTran (None, 24, 32, 256)  1179904     conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 24, 32, 768)  0           block4_conv3[0][0]               \n",
      "                                                                 conv2d_transpose_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 24, 32, 512)  3539456     concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_27 (Conv2DTran (None, 48, 64, 256)  1179904     conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 48, 64, 512)  0           block3_conv3[0][0]               \n",
      "                                                                 conv2d_transpose_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 48, 64, 256)  1179904     concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_28 (Conv2DTran (None, 96, 128, 128) 295040      conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 96, 128, 256) 0           block2_conv2[0][0]               \n",
      "                                                                 conv2d_transpose_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 96, 128, 128) 295040      concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_29 (Conv2DTran (None, 192, 256, 64) 73792       conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 192, 256, 128 0           block1_conv2[0][0]               \n",
      "                                                                 conv2d_transpose_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 192, 256, 32) 36896       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 192, 256, 2)  66          conv2d_40[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,573,858\n",
      "Trainable params: 29,573,858\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vgg_unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "X ~ RGB input image\n",
    "y ~ Target mask (2 classes, foreground & background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch : 1] loss : 112.65571969747543\n",
      "[Epoch : 2] loss : 94.29627734422684\n",
      "[Epoch : 3] loss : 94.28440421819687\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-8374c40a6aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mbg_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfg_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfg_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbg_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m192\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mvgg_unet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[Epoch : \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"] loss : \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-9453096044c8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1693\u001b[0m                                                     class_weight)\n\u001b[0;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for data, mask in zip(augmented_data, augmented_masks):\n",
    "        X = np.expand_dims(data, axis=0)\n",
    "        # Foreground & Background\n",
    "        fg_mask = np.expand_dims(mask, axis=0)\n",
    "        bg_mask = np.abs(1 - fg_mask)\n",
    "        y = np.array([fg_mask, bg_mask]).reshape((1, 192, 256, 2))\n",
    "        loss += vgg_unet.train(X, y)\n",
    "    print(\"[Epoch : \" + str(epoch + 1) + \"] loss : \" + str(loss))\n",
    "elapsed_time = time.process_time() - start_time\n",
    "print(\"Total time : \" + str(round(elapsed_time/60,2)) + \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vgg_unet.predict(np.expand_dims(validate_images[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 192, 256, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.squeeze(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.argmax(x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = x > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(pop, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
